# NIP-0021 - NIP Symbol File System

```
    NIP: 0021
    Title: Symbol File System
    Author: Adri√† Carrera <acarrera@peersyst.com>
    Discussions-To: NEM2 Slack
    Status: Draft
    Type: Standards Track
    Layer: Library
    Created: 2021-06-14
    License: Apache 2.0
    License-Code: Apache-2.0
```


## Table of contents

- [Introduction](#introduction)
- [Specification](#specification)
    * [File system size and capacity](#file-system-size-and-capacity)
    * [File system table](#file-system-table)
    * [File characteristics](#file-characteristics)
    * [File and directory creation and update](#file-and-directory-creation-and-update)
    * [File and directory removal](#file-and-directory-removal)
    * [File reading](#file-reading)
- [Motivation](#motivation)
- [Design Decisions](#design-decisions)
    * [Speed improvement](#speed improvement)
    * [Symbol chain performance](#symbol-chain-performance)
- [Implementation](#implementation)
- [Drawbacks](#drawbacks)
- [History](#history)


## Introduction

This proposal aims to define a file system that runs on the Symbol blockchain. This file system should allow to
create, read, update and delete files and directories. Having this layer in the Symbol chain will allow
to build a big amount of applications on top of it: client-side websites, git version control, backups...

Despite NIP20, NIP21 aims to store bigger files preserving the same performance.

## Specification

This approach uses accounts and metadata. The account is the owner of the file system and its metadata is the space where
the data is stored. Each metadata entry represents a block on the file system, so from now on we will call blocks to metadata entries of the account.
Each block is identified by its metadata key, from now on called block identifier.

### File system size and capacity

- There are a total of 2^64 blocks per file system.
- Each block has a size of 1024 bytes = 1KB (utf8 encoded)
- Total file system logical size is almost unlimited 2^64 * 1KB > 1 Zettabyte. In terms on **real size it is strongly related with
  the Symbol blockchain capacity and performance**.

### File system table

In order to index the files and directories inside the file system, there's a need to reserve
special blocks that will hold meta-information. This meta-information will contain what files and
directories exists in the file system and how they are distributed in the data blocks. There are a few approaches
to save this file system meta-information and there is an open discussion on this. We can find inspiration on
UNIX inodes, FAT tables...

My approach aims for simplicity and it should be iterated to reach a standard:
- File system table is a JSON key-value object
- Each key represents the node name and it can be either a directory or a file
- In the case of the key being a file, the value is an ordered array of block identifiers where the file can be obtained
- In the case of the key being a directory, the value is a key-value object that can contain other files or directories

The result looks like the following
```json5
{
  "personal.txt": ["0000000000000100", "0000000000000103", "00000000000001AA"],
  "documents": {
    "photo.jpg": ["0000000000000FF0"],
    "work": {}
  }
}
```

This file system table is saved on the **reserved first 1024 blocks**, so it can have a size up to 1MB

### File characteristics

Because all the registered bytes in the chain have a cost, there's a need to find the way of optimizing/reducing the amount of data saved. This can be done through compression and
encoding:
- All the files are compressed before being encoded. The compression algorithm used is gzip, but other algorithms may work as well. I found bzip2 a good option too.
- All the files are encoded using utf-8 before being stored. Since the Symbol metadata is using utf-8 encoding for saving the metadata values, this is the best option.

### File and directory creation and update

In order to create files or directories, three operations need to happen:
1. Update the file system table to add the new directory
2. Create Symbol metadata transactions to change the file system table on the blockchain. And in the case of being a file, create Symbol metadata transactions to add/change the file data inside the correct blocks specified on the file system table.
3. Broadcast all the transactions to the network and wait for their confirmation

In order to take advantage of aggregate transaction functionality, all the transactions are wrapped inside an aggregate. In the case of the Symbol mainnet, this number is `100`. So we can wrap up to 100KB per transaction.

### File and directory removal

In the case of file or directory removal there are two options that the user can do:
1. Update just the file system table to remove the logical space of the file or the directory. This doesn't imply removing the block data, just the file system table
2. Update the file system table and the block data.

My current implementation only allows doing the first option, since data on the blockchain is saved forever, it does not make any sense to also remove the block data. Anyone could retrieve it by looking at the history.

### File reading

In order to read a file, you first need to retrieve all the blocks that this file contains. To do so you have to query
the Symbol blockchain to get all the blocks for the block identifiers specified in the file system table.

## Motivation

Extending chain capabilities open new possibilities of products that can be built on top of it.
- Symbol 3.0 web that is queried with namespaces
- Pushing / pulling code that's stored in the chain through svn or git version control systems
- Have a layer to store important document/pdf certificates attached to accounts, mosaics and namespaces

## Design Decisions

There are few design decisions and improvements yet to be done. Those can be split in two categories: Speed improvement and Symbol performance.

### Speed improvement

Currently, blocks are obtained sequentially (in chunks of 100 metadata entries) through Catapult Rest API pagination.
API Rest server serves the metadata paginated and ordered by a custom node identifier, and this identifier is different per each node.
With so metadata pages returned are different between nodes (page 0 from node 1 is different from page 1 fom node 2).
Also individual blocks can only be obtained individually by its block identifier.
This blocks the plugin to parallelize requests in different nodes to speed up the process. In the case of files with big amount of blocks you have
to query blocks one by one or retrieve all the blocks of the account paginated and then filter out the ones that correspond to the file.

However, there are some solutions that can solve this:
1. Create an entrypoint on the Catapult Rest API that given an array of metadata keys (max. length of 100) returns their metadata values.
   If we assume we do 1 request per second, we will be able to reach `100 blocks x 1KB per block = 100KB/s` of download speed which is actually great
   for some type of usages.

2. Allow sorting metadata pages by matadata key. This will probably have performance implications on the mongo, but if we could do that, then we could divide blocks
   in logical sectors that could correspond to those pages. So we would allocate files in sectors and it would be fast to retrieve them.

3. Create a `Symbol File Rest API` that would be connected to a Symbol node API and Mongo and would pre-process the files from the metadata keys. This service would watch the changes
   on the chain and would prepare files and blocks to retrieve them at faster speeds. Probably this would require nodes to have better specs, so would be nice to have
   a system to incentivize the nodes to have this component:
    - Through private or paid API that will only work with custom API keys
    - Decentralized layer 2 system that the user pays an X amount of XYM to the node and the node allows to make requests that are signed with the payer private key

The first and second solutions are more short-term oriented, but we need to discuss if they will affect the performance of the current nodes since it may generate a little bit
of noise. The third option is the way-to-go because it will not affect the performance of the actual nodes but implies more development work.

### Symbol chain performance

There has been some warnings from the core team about storing large file data on the chain:
- https://twitter.com/NCOSIGIMCITYNRE/status/1402952074686603268
- https://twitter.com/NCOSIGIMCITYNRE/status/1402992547127906313

Any thoughts on this topic are more than welcome. The help and guide from the core team would be needed here since I may be loosing some things.

## Implementation

- [x] Symbol File System beta module: [Github](https://github.com/Peersyst/symbol-file-system)

- [x] Symbol File System beta CLI: [Github](https://github.com/Peersyst/symbol-file-system)

- [ ] Symbol File System module

- [ ] Symbol File System CLI

- [ ] Symbol File API Node

- [ ] Symbol Web Browser

There are some implementations going on by other japanese community members that can be found in the following tweets:
- https://twitter.com/AI27982784/status/1396474797291278345?s=20
- https://twitter.com/EUFjZEyIuzS9rIi/status/1396432583362179074
- https://twitter.com/cryptcoin001/status/1402493648642609156?s=20

Would be excellent if we could merge all the work and collaborate together.

## Drawbacks

Symbol blockchain main use case has never been storing data on the chain and there might be some implications on doing so.
As mentioned in the implementation performance topic, some concerns have been raised by the core team around storing data on the main chain.

- The first one is about fees. They could go up very quick since a lot of transactions need to happen in order to store large files.
- Second one is about node performance. Nodes may not be able to process big amounts of data and some transactions may be discarded. However this needs to be
  discussed with the core team.

## References

## History

| **Date**       | **Version**   |
| -------------- | ------------- |
| Jun 14 2020    | Initial Draft |
